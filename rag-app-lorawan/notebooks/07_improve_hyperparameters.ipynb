{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jorge/Library/Caches/pypoetry/virtualenvs/rag-app-lorawan-UNESnz7Y-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.core.node_parser import (\n",
    "    SimpleNodeParser,\n",
    "    SentenceSplitter,\n",
    "    TokenTextSplitter,\n",
    "    SemanticSplitterNodeParser,\n",
    "    MarkdownNodeParser,\n",
    ")\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_qa_csv(file_path: str)-> list[tuple]:\n",
    "    df = pd.read_csv(file_path)\n",
    "    qa_pairs = list(zip(df[\"question\"], df[\"answer\"]))\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevance(response_text, ground_truth_text, evaluation_embed_model):\n",
    "    response_embedding = evaluation_embed_model.get_text_embedding(response_text)\n",
    "    ground_truth_embedding = evaluation_embed_model.get_text_embedding(ground_truth_text)\n",
    "    \n",
    "    similarity = cosine_similarity([response_embedding], [ground_truth_embedding])\n",
    "    return similarity[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_app(index, qa_pairs, evaluation_embed_model, top_k):\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=index,\n",
    "        similarity_top_k=top_k,\n",
    "    )\n",
    "    query_engine = RetrieverQueryEngine(\n",
    "        retriever=retriever,\n",
    "    )\n",
    "    relevance_scores = []\n",
    "\n",
    "    for question, ground_truth in qa_pairs:\n",
    "        response = query_engine.query(question)\n",
    "        response_text = response.response  # Extract the text content\n",
    "        relevance = compute_relevance(response_text, ground_truth, evaluation_embed_model)\n",
    "        relevance_scores.append(relevance)\n",
    "    average_score = sum(relevance_scores) / len(relevance_scores)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(input_dir=\"../data/articles\", recursive=True).load_data()\n",
    "\n",
    "qa_pairs = parse_qa_csv(\"../data/faq/faq_cleaned.csv\")\n",
    "\n",
    "evaluation_embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    embedding_choice = trial.suggest_categorical(\n",
    "        \"embedding_model\", [\"openai\", \"cohere\", \"gemini\"]\n",
    "    )\n",
    "    chunk_size = trial.suggest_int('chunk_size', 256, 1536, step=256)\n",
    "    chunk_overlap = trial.suggest_int(\"chunk_overlap\", 0, 200, step=50)\n",
    "    top_k = trial.suggest_int(\"top_k\", 1, 10)\n",
    "    node_parser_choice = trial.suggest_categorical(\n",
    "        \"node_parser\", [\"simple\", \"sentence\", \"token\", \"semantic\", \"markdown\"]\n",
    "    )\n",
    "    index_type = trial.suggest_categorical(\"index_type\", [\"simple\", \"chromadb\"])\n",
    "\n",
    "    # Select embedding model based on choice\n",
    "    if embedding_choice == \"openai\":\n",
    "        embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "    elif embedding_choice == \"cohere\":\n",
    "        embed_model = CohereEmbedding(\n",
    "            api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "            model_name=\"embed-english-v3.0\",\n",
    "            input_type=\"search_document\",\n",
    "        )\n",
    "    elif embedding_choice == \"gemini\":\n",
    "        embed_model = GeminiEmbedding(\n",
    "            api_key=os.getenv(\"GOOGLE_API_KEY\"), model_name=\"models/embedding-001\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid embedding model selected.\")\n",
    "\n",
    "    # Select node parser based on choice\n",
    "    if node_parser_choice == \"simple\":\n",
    "        node_parser = SimpleNodeParser(chunk_overlap=chunk_overlap, chunk_size=chunk_size)\n",
    "    elif node_parser_choice == \"sentence\":\n",
    "        node_parser = SentenceSplitter(chunk_overlap=chunk_overlap, chunk_size=chunk_size)\n",
    "    elif node_parser_choice == \"token\":\n",
    "        node_parser = TokenTextSplitter(chunk_overlap=chunk_overlap, chunk_size=chunk_size)\n",
    "    elif node_parser_choice == \"semantic\":\n",
    "        buffer_size = trial.suggest_int(\"buffer_size\", 1, 3)\n",
    "        breakpoint_percentile_threshold = trial.suggest_int(\n",
    "            \"breakpoint_percentile_threshold\", 60, 95\n",
    "        )\n",
    "        node_parser = SemanticSplitterNodeParser(\n",
    "            buffer_size=buffer_size,\n",
    "            breakpoint_percentile_threshold=breakpoint_percentile_threshold,\n",
    "            embed_model=embed_model,\n",
    "        )\n",
    "    elif node_parser_choice == \"markdown\":\n",
    "        include_prev_next_rel = trial.suggest_categorical(\n",
    "            \"include_prev_next_rel\", [True, False]\n",
    "        )\n",
    "        node_parser = MarkdownNodeParser(include_prev_next_rel=include_prev_next_rel)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid node parser selected.\")\n",
    "\n",
    "    # Configure the service context\n",
    "    openai_llm = OpenAI(temperature=0.0, model=\"gpt-4o-mini\")\n",
    "    Settings.embed_model = embed_model\n",
    "    Settings.llm = openai_llm\n",
    "    Settings.node_parser = node_parser\n",
    "\n",
    "    # Build the index with the current hyperparameters\n",
    "    index = VectorStoreIndex.from_documents(documents, index_type=index_type)\n",
    "\n",
    "    # Evaluate the index using the evaluation function\n",
    "    score = evaluate_rag_app(index, qa_pairs, evaluation_embed_model, top_k)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name = 'rag_lora_study'\n",
    "storage_name = f\"sqlite:///optuna_{study_name}.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-07 22:28:46,065] A new study created in RDB with name: rag_lora_study\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-07 22:41:01,352] Trial 0 finished with value: 0.8735897514035502 and parameters: {'embedding_model': 'openai', 'chunk_size': 512, 'chunk_overlap': 50, 'top_k': 7, 'node_parser': 'sentence', 'index_type': 'simple'}. Best is trial 0 with value: 0.8735897514035502.\n",
      "[I 2024-10-07 22:53:27,273] Trial 1 finished with value: 0.873839473832013 and parameters: {'embedding_model': 'openai', 'chunk_size': 768, 'chunk_overlap': 150, 'top_k': 6, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-07 23:04:43,541] Trial 2 finished with value: 0.8673895622025561 and parameters: {'embedding_model': 'gemini', 'chunk_size': 512, 'chunk_overlap': 150, 'top_k': 8, 'node_parser': 'markdown', 'index_type': 'chromadb', 'include_prev_next_rel': True}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-07 23:16:32,599] Trial 3 finished with value: 0.8727006220962842 and parameters: {'embedding_model': 'cohere', 'chunk_size': 1024, 'chunk_overlap': 50, 'top_k': 10, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-07 23:25:25,321] Trial 4 finished with value: 0.8623439609805748 and parameters: {'embedding_model': 'gemini', 'chunk_size': 512, 'chunk_overlap': 100, 'top_k': 2, 'node_parser': 'token', 'index_type': 'simple'}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-07 23:36:22,143] Trial 5 finished with value: 0.8638281166906857 and parameters: {'embedding_model': 'gemini', 'chunk_size': 512, 'chunk_overlap': 100, 'top_k': 2, 'node_parser': 'semantic', 'index_type': 'simple', 'buffer_size': 2, 'breakpoint_percentile_threshold': 79}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-07 23:45:45,983] Trial 6 finished with value: 0.8691834456389171 and parameters: {'embedding_model': 'openai', 'chunk_size': 512, 'chunk_overlap': 50, 'top_k': 1, 'node_parser': 'semantic', 'index_type': 'chromadb', 'buffer_size': 2, 'breakpoint_percentile_threshold': 86}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-07 23:56:41,743] Trial 7 finished with value: 0.8735913695399316 and parameters: {'embedding_model': 'openai', 'chunk_size': 1024, 'chunk_overlap': 50, 'top_k': 3, 'node_parser': 'semantic', 'index_type': 'chromadb', 'buffer_size': 1, 'breakpoint_percentile_threshold': 92}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-08 00:08:39,427] Trial 8 finished with value: 0.8651219297457843 and parameters: {'embedding_model': 'cohere', 'chunk_size': 256, 'chunk_overlap': 150, 'top_k': 2, 'node_parser': 'semantic', 'index_type': 'chromadb', 'buffer_size': 3, 'breakpoint_percentile_threshold': 68}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-08 00:20:05,916] Trial 9 finished with value: 0.8683252596161993 and parameters: {'embedding_model': 'gemini', 'chunk_size': 512, 'chunk_overlap': 200, 'top_k': 9, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-08 00:32:49,670] Trial 10 finished with value: 0.8736341362103025 and parameters: {'embedding_model': 'openai', 'chunk_size': 1536, 'chunk_overlap': 200, 'top_k': 5, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 1 with value: 0.873839473832013.\n",
      "[I 2024-10-08 00:44:40,593] Trial 11 finished with value: 0.8749532015924752 and parameters: {'embedding_model': 'openai', 'chunk_size': 1536, 'chunk_overlap': 200, 'top_k': 5, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 00:59:50,153] Trial 12 finished with value: 0.8743139647699608 and parameters: {'embedding_model': 'openai', 'chunk_size': 1536, 'chunk_overlap': 150, 'top_k': 5, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 01:12:29,980] Trial 13 finished with value: 0.8744956328103028 and parameters: {'embedding_model': 'openai', 'chunk_size': 1536, 'chunk_overlap': 200, 'top_k': 4, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 01:21:59,939] Trial 14 finished with value: 0.8741270730701216 and parameters: {'embedding_model': 'openai', 'chunk_size': 1280, 'chunk_overlap': 200, 'top_k': 4, 'node_parser': 'markdown', 'index_type': 'simple', 'include_prev_next_rel': False}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 01:35:38,932] Trial 15 finished with value: 0.8737029961122799 and parameters: {'embedding_model': 'openai', 'chunk_size': 1280, 'chunk_overlap': 0, 'top_k': 4, 'node_parser': 'token', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 01:44:45,889] Trial 16 finished with value: 0.8697686357732818 and parameters: {'embedding_model': 'cohere', 'chunk_size': 1280, 'chunk_overlap': 200, 'top_k': 6, 'node_parser': 'sentence', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 01:59:44,978] Trial 17 finished with value: 0.8742406310340991 and parameters: {'embedding_model': 'openai', 'chunk_size': 1536, 'chunk_overlap': 200, 'top_k': 4, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 02:10:30,817] Trial 18 finished with value: 0.8741263165279913 and parameters: {'embedding_model': 'openai', 'chunk_size': 1280, 'chunk_overlap': 150, 'top_k': 7, 'node_parser': 'simple', 'index_type': 'chromadb'}. Best is trial 11 with value: 0.8749532015924752.\n",
      "[I 2024-10-08 02:17:27,777] Trial 19 finished with value: 0.8681212780169507 and parameters: {'embedding_model': 'cohere', 'chunk_size': 1536, 'chunk_overlap': 100, 'top_k': 3, 'node_parser': 'simple', 'index_type': 'simple'}. Best is trial 11 with value: 0.8749532015924752.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'embedding_model': 'openai', 'chunk_size': 1536, 'chunk_overlap': 200, 'top_k': 5, 'node_parser': 'simple', 'index_type': 'simple'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-app-lorawan-UNESnz7Y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
